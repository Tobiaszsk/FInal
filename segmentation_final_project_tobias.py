# -*- coding: utf-8 -*-
"""Segmentation_Final_Project_Tobias.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gbFC2mYN1EHNxV9ZHK7D1jddRXSnoMnK
"""



# ------ Import module ------
import pandas as pd
import numpy as np
import re

from sklearn.mixture import GaussianMixture
from sklearn.model_selection import train_test_split

from sklearn.preprocessing import OneHotEncoder
from sklearn.cluster import KMeans
import matplotlib.pylab as plt



# ------ Define functions ------
def run_kmeans(n_clusters_f, init_f, df_f):
    # Complete this function
    # This function should at least take a dataframe as an argument. I have suggested additional arguments you may
    # want to provide, but these can be changed as you need to fit your solution.
    # The output of this function should be the input data frame will the model object KMeans and a data summary. The
    # function will need to add an additional column to the input dataframe called 'predict_cluster_kmeans'
    # that contains the cluster labels assigned by the algorithm.
    k_means_model_f = KMeans(n_clusters=n_clusters_f, init=init_f)
    k_means_model_f.fit(df_f)
    df_f['predict_cluster_kmeans'] = k_means_model_f.labels_

    # summarize cluster attributes
    #k_means_model_f_summary = df_f.groupby('predict_cluster_kmeans').agg(attribute_summary_method_dict)
    k_means_model_f_summary = df_f.groupby('predict_cluster_kmeans').agg(np.mean)
    return k_means_model_f, k_means_model_f_summary



# ------ Import data ------
df_subscribers = pd.read_csv('111.csv')
df_subscribers.head(3)

df_subscribers.shape

df_subscribers.columns



# ------ Engineer features -----

corr_df = df_subscribers.drop(columns=['payment_period','num_weekly_services_utilized'])

corr_df = pd.get_dummies(corr_df)
corr_df.columns

corr_df = corr_df.drop(columns=['Gender_male'])

#corr_df['age'] = corr_df[corr_df['age']<100]['age']

corr_df = corr_df.dropna(subset=['weekly_consumption_hour'])

corr_df.isnull().sum()

corr_df.shape



# ------ RUN CLUSTERING -----

# --- set parameters
n_clusters = 5
init_point_selection_method = 'k-means++'





#corr_target = corr_df.corr()[['current_sub_TF']].sort_values('current_sub_TF', ascending=False)

#salient_num_features = corr_target.loc[corr_target['current_sub_TF'] > 0.1, :]
#salient_num_features



# --- select data
# specify list of attributes on which to base clusters
cols_for_clustering_full = corr_df.columns
df_cluster = corr_df.reindex(columns=cols_for_clustering_full)
# df_cluster = df.loc[:, cols_for_clustering]

# --- split to test and train
df_cluster_train, df_cluster_test, _, _, = train_test_split(
    df_cluster, [1]*df_cluster.shape[0], test_size=0.33)   # ignoring y values for unsupervised

# --- fit model
#attribute_summary_method_dict = {'burger': np.mean, 'fries': np.mean, 'salad': np.mean, 'shake': np.mean, 'hour': np.mean, 'store_1': sum,
#                                 'store_4': sum, 'store_6': sum, 'store_3': sum, 'store_9': sum, 'store_2': sum, 'store_8': sum, 'store_5': sum, 'store_7': sum}
#col_output_order = ['burger', 'fries', 'salad', 'shake', 'hour', 'store_1', 'store_2', 'store_3', 'store_4',
#                    'store_5', 'store_6', 'store_7', 'store_8', 'store_9']  # specify order of output columns for easy of readability

# training data
train_model, train_model_summary = run_kmeans(n_clusters, init_point_selection_method, df_cluster_train.reindex())
# testing data
test_model, test_model_summary = run_kmeans(n_clusters, init_point_selection_method, df_cluster_test.reindex())
# all data
model, model_summary = run_kmeans(n_clusters, init_point_selection_method, df_cluster)



# --- run for various number of clusters

# add the code to run the clustering algorithm for various numbers of clusters
ks = range(1, 16)
inertias = []

for k in ks:
    model = KMeans(n_clusters=k, n_init=10)
    model.fit(df_cluster)
    inertias.append(model.inertia_)

# --- draw elbow plot

# create an elbow plot for your numbers of clusters in previous step
plt.figure(figsize=(10,10))
plt.plot(ks, inertias, '-o')
plt.xlabel('number of clusters, k')
plt.ylabel('inertia')
plt.xticks(ks)
plt.show()



# --- output tagged data for examination ----
#store_col_names = ['store_1', 'store_2', 'store_3', 'store_4',
#                   'store_5', 'store_6', 'store_7', 'store_8', 'store_9']
#df_cluster['store'] = None
#for t_col in store_col_names:
#    df_cluster.loc[df_cluster[t_col] == 1, 'store'] = t_col.split('_')[1]

df_cluster.to_csv('clustering_output_tobias.csv')

df_cluster



"""# New Section

# New Section
"""